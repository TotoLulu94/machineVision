%% fit the model to a dataset
function [weight, mean, cov] = fitMixGauss(data,k,nIter)
        
[nDim, nData] = size(data);

%MAIN E-M ROUTINE 
%there are nData data points, and there is a hidden variable associated
%with each.  If the hidden variable is 0 this indicates that the data was
%generated by the first Gaussian.  If the hidden variable is 1 then this
%indicates that the hidden variable was generated by the second Gaussian
%etc.

postHidden = zeros(k, nData);

%in the E-M algorithm, we calculate a complete posterior distribution over
%the (nData) hidden variables in the E-Step.  In the M-Step, we
%update the parameters of the Gaussians (mean, cov, w).  

% we will initialize the values to random values
mixGaussEst.d = nDim;
mixGaussEst.k = k;
mixGaussEst.weight = (1/k)*ones(1,k);
mixGaussEst.mean = 2*randn(nDim,k);
for cGauss =1:k
    mixGaussEst.cov(:,:,cGauss) = (0.5+1.5*rand(1))*eye(nDim,nDim);
end


%calculate current likelihood
logLike = getMixGaussLogLike(data,mixGaussEst);
fprintf('Log Likelihood Iter 0 : %4.3f\n',logLike);



for cIter = 1:nIter
   %Expectation step
   for cData = 1:nData
        %calculate posterior probability that thisData point came from each of the Gaussians
        thisData = data(:,cData);
        for i=1:mixGaussEst.k
            postHidden(i,cData) = mixGaussEst.weight(i)*getGaussProb(thisData, mixGaussEst.mean(:,i), mixGaussEst.cov(:,:,i));
        end
        postHidden(:,cData) = postHidden(:,cData)/sum(postHidden(:,cData));
   end
   
   
   %Maximization Step
   
   %for each constituent Gaussian
   for cGauss = 1:mixGaussEst.k
        %Update weighting parameters mixGauss.weight based on the total
        %posterior probability associated with each Gaussian. 
        mixGaussEst.weight(cGauss) = sum(postHidden(cGauss,:))/sum(sum(postHidden)); 
   
        %Update mean parameters mixGauss.mean by weighted average
        %where weights are given by posterior probability associated with
        %Gaussian.
        mixGaussEst.mean(:,cGauss) =  sum(repmat(postHidden(cGauss,:),3,1).*data,2)/sum(postHidden(cGauss,:)) ;
        
        %Update covarance parameter based on weighted average of
        %square distance from update mean, where weights are given by
        %posterior probability associated with Gaussian
        rCov = zeros(nDim);
        for i=1:nData
           rCov = rCov + postHidden(cGauss,i)*(data(:,i)-mixGaussEst.mean(cGauss))*(data(:,i)-mixGaussEst.mean(cGauss))';
        end
        mixGaussEst.cov(:,:,cGauss) = rCov/sum(postHidden(cGauss,:));
   end
  
   %calculate the log likelihood
   logLike = getMixGaussLogLike(data,mixGaussEst);
   fprintf('Log Likelihood After M-Step Iter %d : %4.3f\n',cIter,logLike);

   %calculate the bound
%    bound = getMixGaussBound(data,mixGaussEst,postHidden);
%    fprintf('Bound After M-Step Iter %d : %4.3f\n',cIter,bound); 
   
end

weight = mixGaussEst.weight ;
mean = mixGaussEst.mean ;
cov = mixGaussEst.cov ;

end

%% the goal of this subroutine is to calculate the log likelihood for the whole
%data set under a mixture of Gaussians model. We calculate the log as the
%likelihood will probably be a very small number that Matlab may not be
%able to represent.
function logLike = getMixGaussLogLike(data,mixGaussEst)

%find total number of data items
[~, nData] = size(data);

%initialize log likelihoods
logLike = 0;

%run through each data item
for cData = 1:nData
    thisData = data(:,cData);    
    %calculate likelihood of this data point under mixture of Gaussians model
    like = 0;
    
    for i=1:mixGaussEst.k    
        like = like + mixGaussEst.weight(i)*getGaussProb(thisData, mixGaussEst.mean(:,i), mixGaussEst.cov(:,:,i));
    end
    
    %add to total log like
    logLike = logLike+log(like);        
end
end

%% subroutine to return gaussian probabilities
function prob = getGaussProb(x,mean,var)
[nDim ~] = size(x);
A = 1/sqrt(det(var));
B = ((x-mean)')*inv(var)*(x-mean);
prob = (A/sqrt((2*pi)^nDim))*exp(-0.5*B);
end

%% calculate the bound
function bound = getMixGaussBound(data,mixGaussEst,responsibilities)

%find total number of data items
nData = size(data,2);

%initialize bound
bound = 0;

%run through each data item
for cData = 1:nData
    %extract this data
    thisData = data(:,cData);    
    %extract this q(h)
    thisQ = responsibilities(:,cData);
    
    %TO DO - calculate contribution to bound of this datapoint
    %Replace this
    boundValue= 0;
    for i=1:mixGaussEst.k
       boundValue = boundValue + thisQ(i)*log(mixGaussEst.weight(i)*getGaussProb(thisData, mixGaussEst.mean(:,i), mixGaussEst.cov(:,:,i))/thisQ(i)); 
    end
    
    %add to total log like
    bound = bound+boundValue;        
end
end